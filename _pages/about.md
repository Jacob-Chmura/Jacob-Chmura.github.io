---
layout: about
title: Home
permalink: /
subtitle:

profile:
  align: center
  image: prof_pic.jpg
  image_circular: true # crops the image to make it circular
  address: üìç Toronto, Canada

news: false # includes a list of news items
latest_posts: false # includes a list of the newest posts
selected_papers: false # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

<hr>

I‚Äôm currently working in [deep reinforcement learning at RBC](https://www.rbccm.com/en/expertise/electronic-trading/ai-trading.page). 
On the research front, I‚Äôm building predictive models that tackle the [order routing problem](https://en.wikipedia.org/wiki/Smart_order_routing) and investigating compression-based self-supervised objectives to accelerate learning in sparse reward environments. 
Previously, I developed a multi-objective reinforcement learning framework *(patent pending)* for personalized trading that enables few-shot adaptation across client trading preferences. 
On the engineering side, I‚Äôm focused on increasing learning throughput, lowering GPU memory requirements in our training stack, and developing architectural changes for efficient market data sequence modelling.

Before RBC, I was a researcher at the [Vector Institute for Artificial Intelligence](https://vectorinstitute.ai/), applying machine learning to solve problems in cancer genomics. 
Specifically, I investigated how Bayesian methods, ensembles, and second-order optimization could reduce rare cancer misclassification. 
I also worked on an [information-theoretic algorithm](https://pubmed.ncbi.nlm.nih.gov/31797603/) that segments the genome based on regional mutation density patterns, reducing the number of mutations required to discriminate cancer types.

My long-term goal is to build embodied decision-making agents that can emulate human-level generality, inspired by the recent advances of [foundation models](https://blogs.nvidia.com/blog/2023/03/13/what-are-foundation-models/). 
My primary research interests lie at the intersection of statistical decision theory, multi-goal reinforcement learning, and self-supervised representation learning. 
In particular, I‚Äôm interested in how we can extract robust behavioural priors from massive offline datasets.

I am also fascinated by the intersection of machine learning and systems, designing a runtime that supports efficient training and inference at scale.
Developing subquadratic attention operators with efficient hardware co-design will be critical for modelling temporal correlations in long-horizon problems.

<hr>
