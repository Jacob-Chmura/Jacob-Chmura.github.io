---
layout: about
title: Home
permalink: /
subtitle:

profile:
  align: center
  image: prof_pic.jpg
  image_circular: true # crops the image to make it circular
  address: üìç Toronto, Canada

news: false # includes a list of news items
latest_posts: false # includes a list of the newest posts
selected_papers: false # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

<hr>

I'm currently working in [applied deep reinforcement learning at RBC](https://www.rbccm.com/en/expertise/electronic-trading/ai-trading.page). My efforts are evenly split between research and engineering. 
On the research front, I'm building predictive models to tackle the [order routing problem](https://en.wikipedia.org/wiki/Smart_order_routing) and
investigating information based solutions to accelerate learning in sparse reward, partially observable environments. 
Previously, I developed a multi-objective reinforcement learning framework *(patent pending)*, that combines bound optimization, hindsight relabelling, gradient projections and vectorized Bellman operators to find policies on the pareto front, enabling few-shot adaptation to linear preferences during inference.
On the engineering side, I'm focusing on increasing training throughput, reducing inference latency, and lowering GPU memory requirements all around.

Before RBC, I was a reseacher at the [Vector Institute for Artificial Intelligence](https://vectorinstitute.ai/), applying machine learning to solve problems in cancer genomics.
Specifically, I investigated the extent to which bayesian methods, ensembles, and second order optimization could reduce rare cancer missclassification rates.
I ran a feature importance analysis, and worked on a information-theoretic algorithm that segments the genome based on regional mutation density patterns, reducing the average number of mutations required to discriminate cancer types.

My primary research interests are statistical decision theory, representation learning, and optimization. In particular, I am interested in how [compression based objectives](https://arxiv.org/pdf/0812.4360.pdf) can give rise to representations that improve sample efficiency and accelerate exploration. 

I am also fascinated by the intersection of machine learning and systems,  designing a runtime that supports efficient training and inference of machine learning models at scale.

<hr>
